# Detailed Implementation Plan: Gemini 2.5 Flash Lite Integration

**Version 1.1** - Updated with fixes and improvements

## 🎯 Goal
Add Google Gemini 2.5 Flash Lite API integration to evolve factorization strategies using LLM-proposed mutations.

## 📝 Updates in v1.1
- ✅ Added directory structure creation instructions
- ✅ Added Pydantic validators for residue range checking
- ✅ Removed unused imports (time module)
- ✅ Improved error handling in response conversion
- ✅ Fixed duration parameter usage throughout code
- ✅ Added API verification step (Phase 1.5)
- ✅ Enhanced .gitignore with common IDE/OS files
- ✅ Added src/__init__.py for proper package structure

## 💡 Why Gemini 2.5 Flash Lite?
- **FREE in free tier** (no cost for development/testing)
- **30-40x cheaper** than Claude in paid tier ($0.10/M input vs $3/M, $0.40/M output vs $15/M)
- **Structured output support** (JSON schema → reliable parsing)
- **Fast & efficient** (optimized for low latency)
- **Large context** (1M input tokens, 65K output tokens)

## 📋 Implementation Phases

### Phase 1: Project Foundation (20 min)
**Setup dependencies and configuration infrastructure**

**First, create directory structure:**
```bash
mkdir -p src/llm tests
touch src/__init__.py
touch src/llm/__init__.py
```

**Files to create:**

1. **`requirements.txt`**:
   ```
   google-genai>=0.2.0
   python-dotenv>=1.0.0
   pydantic>=2.0.0
   pytest>=7.4.0
   ```

2. **`.env.example`**:
   ```
   GEMINI_API_KEY=your_api_key_here
   MAX_LLM_CALLS_PER_RUN=100
   LLM_ENABLED=true
   ```

3. **`.gitignore` additions**:
   ```
   .env
   __pycache__/
   *.pyc
   .pytest_cache/
   *.egg-info/
   .DS_Store
   .vscode/
   .idea/
   logs/
   checkpoints/
   ```

4. **`src/__init__.py`** (empty file)

5. **`src/config.py`**:
   ```python
   from dataclasses import dataclass
   import os
   from dotenv import load_dotenv

   @dataclass
   class Config:
       api_key: str
       max_llm_calls: int = 100
       llm_enabled: bool = True
       temperature_base: float = 0.8
       temperature_max: float = 1.2
       max_tokens: int = 1024

   def load_config() -> Config:
       load_dotenv()
       return Config(
           api_key=os.getenv("GEMINI_API_KEY", ""),
           max_llm_calls=int(os.getenv("MAX_LLM_CALLS_PER_RUN", "100")),
           llm_enabled=os.getenv("LLM_ENABLED", "true").lower() == "true"
       )
   ```

**Deliverable**: Project configured for Gemini API

---

### Phase 1.5: Quick API Verification (5 min)
**Verify Gemini API access before proceeding**

After setting up `.env` with your API key, run this quick test:

```python
# test_api.py
from google import genai

client = genai.Client()
response = client.models.generate_content(
    model="gemini-2.5-flash-lite",
    contents="Say 'API works!' if you can read this."
)
print(response.text)
```

Run:
```bash
python test_api.py
```

Expected output: "API works!" (or similar confirmation)

If this fails:
1. Check GEMINI_API_KEY is set correctly
2. Verify API key at https://aistudio.google.com/app/apikey
3. Ensure `google-genai` is installed: `pip install google-genai`

**Deliverable**: Confirmed API access works

---

### Phase 2: Structured Response Schema (30 min)
**Define Pydantic models for reliable JSON parsing**

**Create `src/llm/schemas.py`**:

```python
from pydantic import BaseModel, Field, field_validator
from typing import Literal, Optional

class PowerMutation(BaseModel):
    new_power: int = Field(..., ge=2, le=5, description="New power value (2-5)")

class AddFilterMutation(BaseModel):
    modulus: int = Field(..., ge=2, le=37, description="Prime modulus")
    residues: list[int] = Field(..., min_length=1, max_length=10, description="Allowed residues")

    @field_validator('residues')
    @classmethod
    def validate_residues(cls, v, info):
        modulus = info.data.get('modulus')
        if modulus and any(r >= modulus or r < 0 for r in v):
            raise ValueError(f"All residues must be in range [0, {modulus})")
        return v

class ModifyFilterMutation(BaseModel):
    index: int = Field(..., ge=0, description="Filter index to modify")
    modulus: int = Field(..., ge=2, le=37)
    residues: list[int] = Field(..., min_length=1, max_length=10)

    @field_validator('residues')
    @classmethod
    def validate_residues(cls, v, info):
        modulus = info.data.get('modulus')
        if modulus and any(r >= modulus or r < 0 for r in v):
            raise ValueError(f"All residues must be in range [0, {modulus})")
        return v

class RemoveFilterMutation(BaseModel):
    index: int = Field(..., ge=0, description="Filter index to remove")

class AdjustSmoothnessMutation(BaseModel):
    bound_delta: int = Field(0, ge=-2, le=2, description="Change to smoothness bound")
    hits_delta: int = Field(0, ge=-1, le=1, description="Change to min hits")

class MutationResponse(BaseModel):
    reasoning: str = Field(..., description="Brief explanation of mutation strategy")
    mutation_type: Literal["power", "add_filter", "modify_filter", "remove_filter", "adjust_smoothness"]

    # Only one of these will be populated based on mutation_type
    power_params: Optional[PowerMutation] = None
    add_filter_params: Optional[AddFilterMutation] = None
    modify_filter_params: Optional[ModifyFilterMutation] = None
    remove_filter_params: Optional[RemoveFilterMutation] = None
    adjust_smoothness_params: Optional[AdjustSmoothnessMutation] = None
```

**Benefits of this approach**:
- Gemini guarantees valid JSON matching this schema
- No manual parsing needed
- Type-safe with validation
- Clear field constraints

**Deliverable**: Type-safe schema for LLM responses

---

### Phase 3: Gemini Client Implementation (45 min)
**Build API client with cost tracking and structured output**

**Create `src/llm/__init__.py`**:
```python
from .base import LLMProvider, LLMResponse
from .gemini import GeminiProvider

__all__ = ["LLMProvider", "LLMResponse", "GeminiProvider"]
```

**Create `src/llm/base.py`**:
```python
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Optional

@dataclass
class LLMResponse:
    success: bool
    mutation_params: dict
    reasoning: Optional[str] = None
    cost: float = 0.0
    input_tokens: int = 0
    output_tokens: int = 0
    error: Optional[str] = None

class LLMProvider(ABC):
    @abstractmethod
    def propose_mutation(
        self,
        parent_strategy: dict,
        fitness: int,
        generation: int,
        fitness_history: list
    ) -> LLMResponse:
        pass

    @property
    @abstractmethod
    def total_cost(self) -> float:
        pass

    @property
    @abstractmethod
    def call_count(self) -> int:
        pass
```

**Create `src/llm/gemini.py`**:
```python
from google import genai
from google.genai import types
from typing import Optional
from .base import LLMProvider, LLMResponse
from .schemas import MutationResponse

class GeminiProvider(LLMProvider):
    def __init__(self, api_key: str, config):
        self.client = genai.Client(api_key=api_key)
        self.config = config
        self._total_cost = 0.0
        self._call_count = 0
        self._input_tokens = 0
        self._output_tokens = 0

    def propose_mutation(
        self,
        parent_strategy: dict,
        fitness: int,
        generation: int,
        fitness_history: list
    ) -> LLMResponse:
        if self._call_count >= self.config.max_llm_calls:
            return LLMResponse(
                success=False,
                mutation_params={},
                error="API call limit reached"
            )

        prompt = self._build_prompt(parent_strategy, fitness, generation, fitness_history)
        temperature = self._calculate_temperature(generation)

        try:
            response = self.client.models.generate_content(
                model="gemini-2.5-flash-lite",
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=temperature,
                    max_output_tokens=self.config.max_tokens,
                    response_mime_type="application/json",
                    response_schema=MutationResponse
                )
            )

            self._call_count += 1

            # Parse structured JSON response
            import json
            mutation_data = json.loads(response.text)

            # Track token usage
            if hasattr(response, 'usage_metadata'):
                input_tokens = response.usage_metadata.prompt_token_count
                output_tokens = response.usage_metadata.candidates_token_count
                self._input_tokens += input_tokens
                self._output_tokens += output_tokens
                cost = self._calculate_cost(input_tokens, output_tokens)
                self._total_cost += cost
            else:
                input_tokens = output_tokens = 0
                cost = 0.0

            # Convert to standard mutation format
            mutation_params = self._convert_response(mutation_data)

            return LLMResponse(
                success=True,
                mutation_params=mutation_params,
                reasoning=mutation_data.get("reasoning", ""),
                cost=cost,
                input_tokens=input_tokens,
                output_tokens=output_tokens
            )

        except Exception as e:
            return LLMResponse(
                success=False,
                mutation_params={},
                error=f"API error: {str(e)}"
            )

    def _build_prompt(
        self,
        parent_strategy: dict,
        fitness: int,
        generation: int,
        fitness_history: list
    ) -> str:
        recent_history = fitness_history[-5:] if len(fitness_history) > 0 else []

        return f"""You are optimizing heuristics for the General Number Field Sieve (GNFS) factorization algorithm.

## Task
Propose a mutation to improve a strategy that identifies "smooth numbers" (numbers with many small prime factors).

## Parent Strategy Performance
- Current fitness: {fitness} candidates found in 0.1 seconds
- Generation: {generation}
- Recent fitness trend: {recent_history}

## Current Strategy Parameters
- **Power**: {parent_strategy['power']} (range: 2-5)
  - Determines the polynomial: x^power - N
  - Lower powers (2-3) are faster, higher powers (4-5) may find better candidates

- **Modulus filters**: {parent_strategy['modulus_filters']}
  - Format: [(modulus, [allowed_residues]), ...]
  - Example: [(3, [0, 1])] means "candidate % 3 must be 0 or 1"
  - These quickly reject non-smooth candidates

- **Smoothness bound**: {parent_strategy['smoothness_bound']}
  - Maximum prime to check for divisibility
  - Available primes: 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37

- **Min small prime hits**: {parent_strategy['min_small_prime_hits']}
  - Minimum count of small prime factors required
  - Higher = more selective, lower = more permissive

## Mutation Strategy Guidelines

**If fitness is LOW (<20)**: Try dramatic changes
- Change power completely
- Add/remove filters to change selectivity
- Adjust smoothness threshold significantly

**If fitness is MODERATE (20-50)**: Experiment with filters
- Add new modulus filters to be more selective
- Adjust existing residue sets
- Fine-tune smoothness parameters

**If fitness is HIGH (>50)**: Make careful refinements
- Small adjustments to existing filters
- Minor smoothness tuning
- Preserve what's working

**Generation context**:
- Early (0-3): Explore diverse approaches, try different powers
- Mid (4-7): Exploit promising patterns, refine filters
- Late (8+): Fine-tune, make minimal changes

## Available Mutations
1. **power**: Change polynomial power
2. **add_filter**: Add new modulus filter (max 4 total)
3. **modify_filter**: Change existing filter's modulus or residues
4. **remove_filter**: Remove a filter (if >1 exists)
5. **adjust_smoothness**: Tweak smoothness_bound and/or min_hits

## Your Task
Analyze the current strategy and propose ONE mutation that is most likely to improve fitness.
Consider: What mathematical properties make numbers smooth? How can modular arithmetic help identify them faster?"""

    def _calculate_temperature(self, generation: int) -> float:
        """Scale temperature: early gens explore (high temp), later exploit (low temp)"""
        progress = min(generation / 10.0, 1.0)
        return self.config.temperature_base + (
            self.config.temperature_max - self.config.temperature_base
        ) * progress

    def _calculate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """
        Gemini 2.5 Flash Lite pricing:
        - Free tier: $0.00 (unlimited within rate limits)
        - Paid tier: $0.10/M input, $0.40/M output

        We estimate paid tier costs for transparency
        """
        input_cost = (input_tokens / 1_000_000) * 0.10
        output_cost = (output_tokens / 1_000_000) * 0.40
        return input_cost + output_cost

    def _convert_response(self, mutation_data: dict) -> dict:
        """Convert structured response to mutation parameters"""
        mutation_type = mutation_data["mutation_type"]

        result = {
            "mutation_type": mutation_type,
            "parameters": {}
        }

        # Map mutation type to corresponding params key
        params_key = f"{mutation_type}_params"
        if params_key in mutation_data and mutation_data[params_key] is not None:
            result["parameters"] = mutation_data[params_key]

        return result

    @property
    def total_cost(self) -> float:
        return self._total_cost

    @property
    def call_count(self) -> int:
        return self._call_count
```

**Deliverable**: Fully functional Gemini API client with structured output

---

### Phase 4: Strategy Generator Integration (45 min)
**Augment StrategyGenerator with LLM capabilities**

**Modify `prototype.py` - Add LLMStrategyGenerator class**:

```python
class LLMStrategyGenerator(StrategyGenerator):
    def __init__(self, llm_provider=None, primes=SMALL_PRIMES):
        super().__init__(primes)
        self.llm_provider = llm_provider
        self.fitness_history = []

    def mutate_strategy_with_context(
        self,
        parent: Strategy,
        fitness: int,
        generation: int
    ) -> Strategy:
        """Try LLM mutation first, fall back to rule-based"""

        # Try LLM if available
        if self.llm_provider:
            response = self.llm_provider.propose_mutation(
                parent_strategy=self._strategy_to_dict(parent),
                fitness=fitness,
                generation=generation,
                fitness_history=self.fitness_history
            )

            if response.success:
                try:
                    child = self._apply_llm_mutation(parent, response.mutation_params)
                    print(f"    [LLM] {response.reasoning}")
                    print(f"    [Cost] ${response.cost:.6f} ({response.input_tokens} in, {response.output_tokens} out)")
                    return child
                except Exception as e:
                    print(f"    [LLM] Failed to apply: {e}, using fallback")

        # Fallback to rule-based
        return super().mutate_strategy(parent)

    def _strategy_to_dict(self, strategy: Strategy) -> dict:
        return {
            "power": strategy.power,
            "modulus_filters": strategy.modulus_filters,
            "smoothness_bound": strategy.smoothness_bound,
            "min_small_prime_hits": strategy.min_small_prime_hits
        }

    def _apply_llm_mutation(self, parent: Strategy, mutation_params: dict) -> Strategy:
        child = parent.copy()
        mutation_type = mutation_params["mutation_type"]
        params = mutation_params["parameters"]

        if mutation_type == "power":
            child.power = params["new_power"]
        elif mutation_type == "add_filter":
            child.modulus_filters.append((params["modulus"], params["residues"]))
        elif mutation_type == "modify_filter":
            idx = params["index"]
            if 0 <= idx < len(child.modulus_filters):
                child.modulus_filters[idx] = (params["modulus"], params["residues"])
        elif mutation_type == "remove_filter" and len(child.modulus_filters) > 1:
            idx = params["index"]
            if 0 <= idx < len(child.modulus_filters):
                child.modulus_filters.pop(idx)
        elif mutation_type == "adjust_smoothness":
            child.smoothness_bound += params.get("bound_delta", 0)
            child.min_small_prime_hits += params.get("hits_delta", 0)

        child._normalize()
        return child

    def record_fitness(self, fitness: int):
        self.fitness_history.append(fitness)
```

**Update EvolutionaryEngine**:

```python
class EvolutionaryEngine:
    def __init__(self, crucible, population_size=10, llm_provider=None, evaluation_duration=0.1):
        self.crucible = crucible
        self.population_size = population_size
        self.civilizations = {}
        self.generation = 0
        self.generator = LLMStrategyGenerator(llm_provider=llm_provider)
        self.evaluation_duration = evaluation_duration

    def run_evolutionary_cycle(self):
        print(f"\n{'='*70}")
        print(f"Generation {self.generation}: Evaluating {self.population_size} Strategies")
        print('='*70)

        # Evaluate all strategies
        for civ_id, civ_data in self.civilizations.items():
            strategy = civ_data["strategy"]
            fitness = self.crucible.evaluate_strategy(strategy, duration_seconds=self.evaluation_duration)
            civ_data["fitness"] = fitness
            self.generator.record_fitness(fitness)

            print(f"  {civ_id}: Fitness={fitness:<4} | {strategy.describe()}")

        # Select elites
        sorted_civs = sorted(
            self.civilizations.items(),
            key=lambda item: item[1]['fitness'],
            reverse=True
        )
        num_elites = max(1, int(self.population_size * 0.2))
        elites = sorted_civs[:num_elites]

        best_civ = elites[0]
        print(f"\n  🏆 Best: {best_civ[0]} with fitness {best_civ[1]['fitness']}")

        # Reproduce
        next_generation_civs = {}
        for i in range(self.population_size):
            parent_civ = random.choice(elites)
            parent_strategy = parent_civ[1]['strategy']
            parent_fitness = parent_civ[1]['fitness']

            new_civ_id = f"civ_{self.generation + 1}_{i}"

            if random.random() < 0.2:
                # 20% fresh random strategies
                new_strategy = self.generator.random_strategy()
                print(f"  {new_civ_id}: Random strategy")
            else:
                # 80% mutations (LLM or rule-based)
                new_strategy = self.generator.mutate_strategy_with_context(
                    parent_strategy,
                    parent_fitness,
                    self.generation
                )

            next_generation_civs[new_civ_id] = {"strategy": new_strategy, "fitness": 0}

        self.civilizations = next_generation_civs
        self.generation += 1
```

**Deliverable**: Integrated LLM mutations into evolution engine

---

### Phase 5: Main Script & CLI (30 min)
**Update main execution with LLM support**

**Add to `prototype.py`**:

```python
if __name__ == "__main__":
    import argparse
    import sys

    parser = argparse.ArgumentParser(
        description="GNFS Strategy Evolution with LLM",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Rule-based evolution (no LLM)
  python prototype.py --number 961730063 --generations 5

  # LLM-driven evolution
  python prototype.py --llm --generations 10 --population 20

  # Custom number with LLM
  python prototype.py --llm --number 1234567 --generations 5
        """
    )
    parser.add_argument("--number", type=int, default=961730063,
                       help="Number to factor (default: 961730063)")
    parser.add_argument("--generations", type=int, default=5,
                       help="Number of generations (default: 5)")
    parser.add_argument("--population", type=int, default=10,
                       help="Population size (default: 10)")
    parser.add_argument("--llm", action="store_true",
                       help="Enable LLM mutations (requires GEMINI_API_KEY)")
    parser.add_argument("--duration", type=float, default=0.1,
                       help="Evaluation duration per strategy in seconds (default: 0.1)")

    args = parser.parse_args()

    # Initialize LLM provider if enabled
    llm_provider = None
    if args.llm:
        try:
            from src.config import load_config
            from src.llm import GeminiProvider

            config = load_config()
            if not config.api_key:
                print("[ERROR] No GEMINI_API_KEY found in environment")
                print("Please set GEMINI_API_KEY or create .env file")
                sys.exit(1)

            llm_provider = GeminiProvider(config.api_key, config)
            print(f"[LLM MODE ENABLED]")
            print(f"  Model: gemini-2.5-flash-lite")
            print(f"  Max calls: {config.max_llm_calls}")
            print(f"  Temperature: {config.temperature_base} -> {config.temperature_max}")
            print()

        except ImportError as e:
            print(f"[ERROR] Failed to load LLM modules: {e}")
            print("Run: pip install -r requirements.txt")
            sys.exit(1)
    else:
        print("[RULE-BASED MODE]")
        print("  Using hardcoded mutation rules")
        print("  Add --llm flag to enable AI-driven mutations")
        print()

    # Run evolution
    print(f"Target Number: {args.number}")
    print(f"Generations: {args.generations}")
    print(f"Population: {args.population}")
    print(f"Evaluation Duration: {args.duration}s per strategy")
    print()

    crucible = FactorizationCrucible(args.number)
    engine = EvolutionaryEngine(
        crucible,
        args.population,
        llm_provider,
        evaluation_duration=args.duration
    )

    engine.initialize_population()

    import time
    start_time = time.time()

    for gen in range(args.generations):
        engine.run_evolutionary_cycle()

    elapsed = time.time() - start_time

    # Summary
    print(f"\n{'='*70}")
    print("EVOLUTION COMPLETE")
    print('='*70)
    print(f"Total time: {elapsed:.2f}s")

    if llm_provider:
        print(f"\n[LLM STATISTICS]")
        print(f"  API calls: {llm_provider.call_count}")
        print(f"  Total cost: ${llm_provider.total_cost:.4f}")
        print(f"  Avg cost/call: ${llm_provider.total_cost/max(1, llm_provider.call_count):.6f}")

        if llm_provider.total_cost == 0:
            print(f"  Note: Using FREE tier (may have rate limits)")
```

**Deliverable**: Complete CLI with LLM toggle

---

### Phase 6: Testing (30 min)

**Create `tests/test_gemini_integration.py`**:

```python
import pytest
import os
from src.config import Config
from src.llm import GeminiProvider

def test_config_loading():
    """Test configuration loads correctly"""
    config = Config(api_key="test-key-123", max_llm_calls=50)
    assert config.api_key == "test-key-123"
    assert config.max_llm_calls == 50

def test_gemini_provider_init():
    """Test provider initialization"""
    config = Config(api_key="test-key")
    provider = GeminiProvider("test-key", config)
    assert provider.call_count == 0
    assert provider.total_cost == 0.0

@pytest.mark.skipif(
    not os.getenv("GEMINI_API_KEY"),
    reason="No GEMINI_API_KEY environment variable"
)
def test_real_gemini_call():
    """Integration test with real API (requires GEMINI_API_KEY)"""
    from src.config import load_config

    config = load_config()
    provider = GeminiProvider(config.api_key, config)

    parent = {
        "power": 2,
        "modulus_filters": [(3, [0, 1]), (5, [0])],
        "smoothness_bound": 13,
        "min_small_prime_hits": 2
    }

    response = provider.propose_mutation(parent, 45, 3, [30, 35, 40, 42, 45])

    assert response.success, f"API call failed: {response.error}"
    assert response.mutation_params is not None
    assert "mutation_type" in response.mutation_params
    assert response.reasoning is not None

    print(f"\n[Test API Call Results]")
    print(f"  Mutation type: {response.mutation_params['mutation_type']}")
    print(f"  Reasoning: {response.reasoning}")
    print(f"  Cost: ${response.cost:.6f}")
    print(f"  Tokens: {response.input_tokens} in, {response.output_tokens} out")

def test_temperature_scaling():
    """Test temperature increases with generation"""
    config = Config(api_key="test", temperature_base=0.8, temperature_max=1.2)
    provider = GeminiProvider("test", config)

    temp_gen_0 = provider._calculate_temperature(0)
    temp_gen_5 = provider._calculate_temperature(5)
    temp_gen_10 = provider._calculate_temperature(10)

    assert temp_gen_0 == 0.8  # Start at base
    assert 0.8 < temp_gen_5 < 1.2  # Mid-range
    assert temp_gen_10 == 1.2  # Max at gen 10+
```

**Run tests**:
```bash
# Unit tests (no API needed)
pytest tests/test_gemini_integration.py -v -k "not real"

# Integration test (with API key)
GEMINI_API_KEY=your_key pytest tests/test_gemini_integration.py -v
```

**Deliverable**: Validated integration works

---

### Phase 7: Documentation (20 min)

**Update `README.md`**:

```markdown
# Project Prometheus: GNFS Strategy Evolution

AI-driven evolution of factorization heuristics using Gemini 2.5 Flash Lite.

## 🚀 Quick Start

### Setup
```bash
# Install dependencies
pip install -r requirements.txt

# Get free API key from Google AI Studio
# https://aistudio.google.com/app/apikey

# Configure
cp .env.example .env
# Edit .env and add: GEMINI_API_KEY=your_key_here
```

### Run Without LLM (Rule-Based Evolution)
```bash
python prototype.py --number 961730063 --generations 5
```

### Run With LLM (AI-Driven Evolution)
```bash
python prototype.py --llm --number 961730063 --generations 10 --population 20
```

## 💰 Cost Information

**Gemini 2.5 Flash Lite Pricing**:
- **Free Tier**: Unlimited usage within rate limits (60 requests/minute)
- **Paid Tier**: $0.10 per 1M input tokens, $0.40 per 1M output tokens

**Typical Costs**:
- Small run (5 gen, 10 pop): **FREE** (~40 API calls)
- Medium run (10 gen, 20 pop): **$0.05-0.10** (~160 calls)
- Large run (20 gen, 50 pop): **$0.50-1.00** (~800 calls)

**Each mutation**: ~$0.0001-0.0005 (effectively free during development)

## 📊 Example Output

```
[LLM MODE ENABLED]
  Model: gemini-2.5-flash-lite
  Max calls: 100
  Temperature: 0.8 -> 1.2

Target Number: 961730063
Generations: 5
Population: 10

======================================================================
Generation 0: Evaluating 10 Strategies
======================================================================
  civ_0_0: Fitness=45   | power=2, filters=[%3 in (0,1), %5 in (0)], ...
  civ_0_1: Fitness=32   | power=3, filters=[%7 in (0,2,3)], ...
  ...

  🏆 Best: civ_0_0 with fitness 45

  civ_1_0: Random strategy
  civ_1_1:
    [LLM] Adjusting smoothness bound to be more permissive since fitness is moderate
    [Cost] $0.000123 (856 in, 89 out)
  ...

[LLM STATISTICS]
  API calls: 36
  Total cost: $0.0042
  Avg cost/call: $0.000117
  Note: Using FREE tier (may have rate limits)
```

## 🏗️ Project Structure

```
.
├── prototype.py          # Main evolution engine
├── src/
│   ├── config.py        # Configuration management
│   └── llm/
│       ├── base.py      # Abstract LLM interface
│       ├── gemini.py    # Gemini API client
│       └── schemas.py   # Pydantic response schemas
├── tests/
│   └── test_gemini_integration.py
├── requirements.txt
└── .env.example
```

## 🧪 Testing

```bash
# Unit tests
pytest tests/ -v

# Integration test (requires API key)
GEMINI_API_KEY=your_key pytest tests/ -v

# Run prototype without API key
python prototype.py --generations 3
```

## 📝 CLI Options

```
--number N              Number to factor (default: 961730063)
--generations N         Evolution cycles (default: 5)
--population N          Population size (default: 10)
--llm                   Enable LLM mutations (needs GEMINI_API_KEY)
--duration SECS         Evaluation time per strategy (default: 0.1)
```

## 🎯 What This Does

1. **Generates** random factorization strategies (modular filters, polynomial powers)
2. **Evaluates** each strategy by counting smooth number candidates found
3. **Selects** top 20% performers as "elites"
4. **Mutates** elite strategies using:
   - **LLM mode**: Gemini proposes intelligent mutations based on performance
   - **Rule mode**: Hardcoded genetic operators
5. **Repeats** for N generations

## 🔬 Research Goal

Validate that LLM-driven evolution can discover non-obvious algorithmic optimizations
better than rule-based genetic algorithms.

## 📚 Learn More

- [Project Vision](big_picture.md)
- [Implementation Plan](plan_20251024.md)
- [Gemini API Docs](https://ai.google.dev/gemini-api/docs)
```

**Deliverable**: Complete documentation

---

## 📊 Success Metrics

1. ✅ **API works**: >90% success rate on calls
2. ✅ **Structured output**: 100% valid JSON responses
3. ✅ **Cost-effective**: <$0.0005 per mutation
4. ✅ **Fitness improves**: LLM mode beats rule-based by 10%+ after 10 generations
5. ✅ **Free tier viable**: Can run 50+ mutations without hitting rate limits

---

## ⏱️ Total Timeline

- Phase 1: 20 min (setup + directory structure)
- Phase 1.5: 5 min (API verification)
- Phase 2: 30 min (schemas with validators)
- Phase 3: 45 min (Gemini client)
- Phase 4: 45 min (integration)
- Phase 5: 30 min (CLI with duration parameter)
- Phase 6: 30 min (tests)
- Phase 7: 20 min (docs)

**Total: ~3.7 hours**

---

## 💰 Estimated Costs

- **Development/testing**: FREE (free tier covers all development)
- **Validation runs**: $0.00-0.20 total
- **Production experiments**: ~$0.10 per 100 mutations

**Total project cost: < $1.00** (likely $0 if staying in free tier)

---

## 🎁 Benefits vs Claude Plan

| Aspect | Claude | Gemini 2.5 Flash Lite |
|--------|--------|----------------------|
| **Cost** | $0.01-0.02/call | FREE (or $0.0001-0.0005/call) |
| **Development** | $0.50-2.00 | $0.00 |
| **Structured Output** | Manual parsing | Native JSON schema |
| **Context Window** | 200K | 1M tokens |
| **Speed** | Fast | Optimized for latency |
| **Free Tier** | No | Yes (60 RPM) |

**Savings: 30-40x cheaper + FREE tier for unlimited development!**
