{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution Comparison Results Visualization\n",
    "\n",
    "Visualizes statistical comparison of evolved strategies vs classical GNFS-inspired baselines.\n",
    "\n",
    "**Data source**: JSON files exported via `python prototype.py --compare-baseline --export-comparison results/comparison.json`\n",
    "\n",
    "**Analysis includes**:\n",
    "- Fitness evolution trajectories (evolved vs 3 baselines)\n",
    "- Statistical significance testing (Welch's t-test, p-values)\n",
    "- Effect size analysis (Cohen's d)\n",
    "- Convergence detection results\n",
    "- Run-to-run consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 7)\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "# Helper function\n",
    "def significance_stars(p_value):\n",
    "    \"\"\"Convert p-value to significance stars.\"\"\"\n",
    "    if p_value < 0.001:\n",
    "        return \"***\"\n",
    "    elif p_value < 0.01:\n",
    "        return \"**\"\n",
    "    elif p_value < 0.05:\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"ns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load Comparison Data\ncomparison_file = \"../results/test_comparison.json\"  # Adjust path as needed\nwith open(comparison_file) as f:\n    data = json.load(f)\n\n# Extract metadata with safe defaults\nprint(f\"\ud83d\udcca Comparison Analysis\")\nprint(f\"Target number: {data.get('target_number', 'N/A')}\")\nprint(f\"Number of runs: {data.get('num_runs', 0)}\")\nprint(f\"Max generations: {data.get('max_generations', 0)}\")\nprint(f\"Population size: {data.get('population_size', 0)}\")\nprint(f\"Base seed: {data.get('base_seed', 'None')}\")\nprint()\n\nruns = data.get(\"runs\", [])\nanalysis = data.get(\"analysis\", {})\nbaseline_names = [\"conservative\", \"balanced\", \"aggressive\"]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fitness Evolution Over Generations\n",
    "\n",
    "Shows how evolved strategies improve across generations compared to fixed baseline strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(14, 7))\n\n# Extract all evolved fitness trajectories\nall_evolved = [run[\"evolved_fitness\"] for run in runs]\n\n# Check if we have any runs\nif not all_evolved:\n    print(\"\u26a0\ufe0f  No runs found in data. Skipping fitness evolution plot.\")\n    plt.close()\nelse:\n    max_gens = max((len(f) for f in all_evolved), default=0)\n    generations = range(max_gens)\n\n    # Plot individual runs (semi-transparent)\n    for i, fitness in enumerate(all_evolved):\n        gens = range(len(fitness))\n        label = '_nolegend_' if i > 0 else 'Evolved strategies'\n        ax.plot(gens, fitness, 'b-', alpha=0.25, linewidth=1, label=label)\n\n    # Calculate and plot mean trajectory\n    mean_trajectory = []\n    std_trajectory = []\n    for gen in generations:\n        gen_values = [f[gen] for f in all_evolved if len(f) > gen]\n        mean_trajectory.append(np.mean(gen_values))\n        std_trajectory.append(np.std(gen_values))\n\n    ax.plot(generations, mean_trajectory, 'b-', linewidth=2.5, label='Evolved (mean)', zorder=10)\n    ax.fill_between(generations,\n                    np.array(mean_trajectory) - np.array(std_trajectory),\n                    np.array(mean_trajectory) + np.array(std_trajectory),\n                    alpha=0.2, color='blue', label='\u00b11 std dev')\n\n    # Plot baseline horizontal lines\n    baseline_colors = {'conservative': '#d62728', 'balanced': '#ff7f0e', 'aggressive': '#2ca02c'}\n    for name in baseline_names:\n        baseline_val = runs[0][\"baseline_fitness\"][name]\n        ax.axhline(baseline_val, linestyle='--', linewidth=2,\n                   color=baseline_colors[name], alpha=0.8,\n                   label=f'{name.title()} baseline (fitness={baseline_val:.0f})')\n\n    # Mark convergence points\n    for run in runs:\n        if run[\"generations_to_convergence\"] is not None:\n            conv_gen = run[\"generations_to_convergence\"]\n            conv_fitness = run[\"evolved_fitness\"][conv_gen]\n            ax.plot(conv_gen, conv_fitness, 'ro', markersize=6, alpha=0.5, zorder=5)\n\n    # Add first convergence point to legend\n    first_conv = next((r for r in runs if r[\"generations_to_convergence\"] is not None), None)\n    if first_conv:\n        ax.plot([], [], 'ro', markersize=6, alpha=0.5, label='Convergence point')\n\n    ax.set_xlabel('Generation', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Fitness (Smooth Candidates Found)', fontsize=12, fontweight='bold')\n    ax.set_title('Fitness Evolution: Evolved Strategies vs Classical Baselines',\n                 fontsize=14, fontweight='bold')\n    ax.legend(loc='lower right', fontsize=10)\n    ax.grid(alpha=0.3)\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical Comparison\n",
    "\n",
    "Bar chart showing mean fitness with confidence intervals and statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(12, 7))\n\n\n\nx_pos = np.arange(len(baseline_names))\n\nwidth = 0.35\n\n\n\n# Extract means and CIs\n\nevolved_means = [analysis[\"comparison_results\"][name][\"evolved_mean\"] for name in baseline_names]\n\nbaseline_means = [analysis[\"comparison_results\"][name][\"baseline_mean\"] for name in baseline_names]\n\np_values = [analysis[\"comparison_results\"][name][\"p_value\"] for name in baseline_names]\n\neffect_sizes = [analysis[\"comparison_results\"][name][\"effect_size\"] for name in baseline_names]\n\ncis = [analysis[\"comparison_results\"][name][\"confidence_interval\"] for name in baseline_names]\n\n\n\n# Calculate CI errors (distance from mean to bounds)\n\nci_errors = [[(mean - ci[0]), (ci[1] - mean)] for mean, ci in zip(evolved_means, cis)]\n\nci_lower = [e[0] for e in ci_errors]\n\nci_upper = [e[1] for e in ci_errors]\n\n\n\n# Create bars\n\nbars1 = ax.bar(x_pos - width/2, evolved_means, width, label='Evolved', \n\n               color='#1f77b4', alpha=0.8, yerr=[ci_lower, ci_upper], capsize=5)\n\nbars2 = ax.bar(x_pos + width/2, baseline_means, width, label='Baseline',\n\n               color='#7f7f7f', alpha=0.6)\n\n\n\n# Add improvement percentage and significance annotations\n\nfor i, (name, evolved, baseline, p_val, effect) in enumerate(zip(\n\n    baseline_names, evolved_means, baseline_means, p_values, effect_sizes)):\n\n    \n\n    # Improvement percentage\n\n    if baseline > 0:\n\n        improvement = ((evolved - baseline) / baseline) * 100\n\n        imp_text = f\"+{improvement:.1f}%\"\n\n    else:\n\n        imp_text = \"+inf%\"\n\n    \n\n    # Position text above taller bar\n\n    y_pos = max(evolved, baseline) + (max(ci_upper) if ci_upper else 0) * 0.1\n\n    \n\n    # Annotation with significance and effect size\n\n    sig = significance_stars(p_val)\n\n    ax.text(i, y_pos, f\"{imp_text} {sig}\\n(d={effect:.2f})\", \n\n            ha='center', va='bottom', fontsize=9, fontweight='bold')\n\n\n\nax.set_xlabel('Baseline Strategy', fontsize=12, fontweight='bold')\n\nax.set_ylabel('Mean Fitness', fontsize=12, fontweight='bold')\n\nax.set_title('Statistical Comparison: Evolved vs Baseline Strategies', \n\n             fontsize=14, fontweight='bold')\n\nax.set_xticks(x_pos)\n\nax.set_xticklabels([name.title() for name in baseline_names])\n\nax.legend(fontsize=11)\n\nax.grid(alpha=0.3, axis='y')\n\n\n\n# Add significance legend\n\nsig_text = \"Significance: *** p<0.001, ** p<0.01, * p<0.05, ns = not significant\"\n\nax.text(0.02, 0.98, sig_text, transform=ax.transAxes, fontsize=9,\n\n        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n\n\n\nplt.tight_layout()\n\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Effect Size Analysis\n",
    "\n",
    "Quantifies practical significance using Cohen's d. Large effect sizes (d \u2265 0.8) indicate substantial improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "effect_sizes = [analysis[\"comparison_results\"][name][\"effect_size\"] for name in baseline_names]\n",
    "\n",
    "# Color code by effect size magnitude\n",
    "colors = []\n",
    "for d in effect_sizes:\n",
    "    if abs(d) >= 0.8:\n",
    "        colors.append('#2ca02c')  # Large - green\n",
    "    elif abs(d) >= 0.5:\n",
    "        colors.append('#ff7f0e')  # Medium - orange\n",
    "    elif abs(d) >= 0.2:\n",
    "        colors.append('#ffbb00')  # Small - yellow\n",
    "    else:\n",
    "        colors.append('#7f7f7f')  # Negligible - gray\n",
    "\n",
    "bars = ax.barh(baseline_names, effect_sizes, color=colors, alpha=0.7)\n",
    "\n",
    "# Add reference lines for Cohen's d thresholds\n",
    "ax.axvline(0.2, color='gray', linestyle=':', alpha=0.5, label='Small (0.2)')\n",
    "ax.axvline(0.5, color='gray', linestyle='--', alpha=0.5, label='Medium (0.5)')\n",
    "ax.axvline(0.8, color='gray', linestyle='-', alpha=0.5, label='Large (0.8)')\n",
    "\n",
    "# Annotate bars with values\n",
    "for i, (name, d) in enumerate(zip(baseline_names, effect_sizes)):\n",
    "    label_pos = d + 0.1 if d > 0 else d - 0.1\n",
    "    ha = 'left' if d > 0 else 'right'\n",
    "    ax.text(label_pos, i, f\"{d:.2f}\", va='center', ha=ha, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel(\"Cohen's d (Effect Size)\", fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Baseline Strategy', fontsize=12, fontweight='bold')\n",
    "ax.set_title(\"Effect Size Analysis: Practical Significance of Improvements\", \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_yticklabels([name.title() for name in baseline_names])\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.grid(alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convergence Analysis\n",
    "\n",
    "Shows when fitness plateaus occur, indicating stable evolved strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 6))\n\n\n\n# Extract convergence data\n\nconvergence_gens = [run[\"generations_to_convergence\"] for run in runs]\n\nconverged = [g for g in convergence_gens if g is not None]\n\nnot_converged_count = len([g for g in convergence_gens if g is None])\n\n\n\n# Histogram of convergence generations\n\nif converged:\n\n    bins = range(min(converged), max(converged)+2) if len(set(converged)) > 1 else [min(converged), min(converged)+1]\n\n    ax.hist(converged, bins=bins, \n\n            color='#1f77b4', alpha=0.7, edgecolor='black')\n\n    \n\n    # Mean convergence line\n\n    mean_conv = np.mean(converged)\n\n    ax.axvline(mean_conv, color='red', linestyle='--', linewidth=2,\n\n               label=f'Mean convergence: {mean_conv:.1f} gen')\n\n\n\n# Statistics text\n\nconv_stats = analysis[\"convergence_stats\"]\n\nstats_text = (f\"Convergence Rate: {conv_stats['convergence_rate']*100:.0f}%\\n\"\n\n              f\"Mean: {conv_stats['mean']:.1f} \u00b1 {conv_stats['std']:.1f} generations\\n\"\n\n              f\"Did not converge: {not_converged_count} runs\")\n\n\n\nax.text(0.98, 0.98, stats_text, transform=ax.transAxes, fontsize=11,\n\n        verticalalignment='top', horizontalalignment='right',\n\n        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n\n\n\nax.set_xlabel('Generation Number', fontsize=12, fontweight='bold')\n\nax.set_ylabel('Number of Runs', fontsize=12, fontweight='bold')\n\nax.set_title('Convergence Analysis: When Does Fitness Plateau?', \n\n             fontsize=14, fontweight='bold')\n\nif converged:\n\n    ax.legend(fontsize=11)\n\nax.grid(alpha=0.3, axis='y')\n\nplt.tight_layout()\n\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Improvement Distribution\n",
    "\n",
    "Box plots show consistency of improvement across multiple independent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Calculate improvement for each run and each baseline\n",
    "improvements_by_baseline = {name: [] for name in baseline_names}\n",
    "\n",
    "for run in runs:\n",
    "    final_fitness = run[\"evolved_fitness\"][-1]\n",
    "    for name in baseline_names:\n",
    "        baseline_val = run[\"baseline_fitness\"][name]\n",
    "        if baseline_val > 0:\n",
    "            improvement_pct = ((final_fitness - baseline_val) / baseline_val) * 100\n",
    "        else:\n",
    "            improvement_pct = float('inf') if final_fitness > 0 else 0\n",
    "        \n",
    "        # Cap infinite values for display\n",
    "        if improvement_pct == float('inf'):\n",
    "            improvement_pct = 1000  # Display as 1000% for visualization\n",
    "        \n",
    "        improvements_by_baseline[name].append(improvement_pct)\n",
    "\n",
    "# Create box plot\n",
    "positions = range(1, len(baseline_names) + 1)\n",
    "bp = ax.boxplot([improvements_by_baseline[name] for name in baseline_names],\n",
    "                 positions=positions, widths=0.6, patch_artist=True,\n",
    "                 boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                 medianprops=dict(color='red', linewidth=2))\n",
    "\n",
    "# Add individual points\n",
    "for i, name in enumerate(baseline_names, 1):\n",
    "    y = improvements_by_baseline[name]\n",
    "    x = np.random.normal(i, 0.04, size=len(y))\n",
    "    ax.plot(x, y, 'o', alpha=0.4, color='navy', markersize=6)\n",
    "\n",
    "ax.axhline(0, color='gray', linestyle='--', alpha=0.5, label='No improvement')\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels([name.title() for name in baseline_names])\n",
    "ax.set_xlabel('Baseline Strategy', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Improvement (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Improvement Distribution Across Runs', fontsize=14, fontweight='bold')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "# Add note about infinite values\n",
    "if any(1000 in improvements_by_baseline[name] for name in baseline_names):\n",
    "    note_text = \"Note: Baseline=0 cases shown as 1000% for visualization (actually +inf%)\"\n",
    "    ax.text(0.5, 0.02, note_text, transform=ax.transAxes, fontsize=9,\n",
    "            ha='center', va='bottom', style='italic',\n",
    "            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics\n",
    "\n",
    "Complete statistical report for all baseline comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\n\nprint(\"SUMMARY STATISTICS TABLE\")\n\nprint(\"=\" * 80)\n\nprint()\n\n\n\nfor name in baseline_names:\n\n    result = analysis[\"comparison_results\"][name]\n\n    print(f\"{name.upper()} BASELINE:\")\n\n    print(f\"  Evolved mean:  {result['evolved_mean']:.1f}\")\n\n    print(f\"  Baseline mean: {result['baseline_mean']:.1f}\")\n\n    \n\n    if result['baseline_mean'] > 0:\n\n        improvement = ((result['evolved_mean'] - result['baseline_mean']) / result['baseline_mean']) * 100\n\n        print(f\"  Improvement:   +{improvement:.1f}%\")\n\n    else:\n\n        print(f\"  Improvement:   +inf%\")\n\n    \n\n    sig = \"\u2713 YES\" if result['is_significant'] else \"\u2717 NO\"\n\n    print(f\"  p-value:       {result['p_value']:.4f} ({sig})\")\n\n    print(f\"  Effect size:   {result['effect_size']:.2f} (Cohen's d)\")\n\n    print(f\"  95% CI:        [{result['confidence_interval'][0]:.1f}, {result['confidence_interval'][1]:.1f}]\")\n\n    print()\n\n\n\nprint(\"=\" * 80)\n\nprint(\"CONVERGENCE STATISTICS:\")\n\nprint(\"=\" * 80)\n\nconv = analysis[\"convergence_stats\"]\n\nprint(f\"  Convergence rate: {conv['convergence_rate']*100:.0f}% ({int(conv['convergence_rate']*data['num_runs'])}/{data['num_runs']} runs)\")\n\nprint(f\"  Mean generations: {conv['mean']:.1f} \u00b1 {conv['std']:.1f}\")\n\nprint()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca How to Interpret Results\n",
    "\n",
    "### Statistical Significance (p-value)\n",
    "- **p < 0.05**: Statistically significant improvement (marked with *)\n",
    "- **p < 0.01**: Highly significant (**)\n",
    "- **p < 0.001**: Very highly significant (***)\n",
    "- **p \u2265 0.05**: Not statistically significant (ns) - difference could be due to chance\n",
    "\n",
    "### Effect Size (Cohen's d)\n",
    "- **d < 0.2**: Negligible practical difference\n",
    "- **0.2 \u2264 d < 0.5**: Small but meaningful improvement\n",
    "- **0.5 \u2264 d < 0.8**: Medium improvement - noticeable in practice\n",
    "- **d \u2265 0.8**: Large improvement - substantial practical significance\n",
    "\n",
    "### Confidence Interval (95% CI)\n",
    "- Range where the true difference likely falls\n",
    "- If CI excludes 0, the improvement is statistically significant\n",
    "- Wider CI = more uncertainty (fewer runs or high variance)\n",
    "\n",
    "### Convergence\n",
    "- **High convergence rate** (>70%): Evolution reliably finds stable solutions\n",
    "- **Low mean generations**: Fast convergence - efficient optimization\n",
    "- **Non-convergence**: Fitness still improving - may need more generations\n",
    "\n",
    "### Key Questions to Ask\n",
    "1. Did evolution beat all baselines significantly?\n",
    "2. Are effect sizes large enough to matter practically?\n",
    "3. Is improvement consistent across runs (narrow box plots)?\n",
    "4. Does convergence happen early enough for efficiency?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}