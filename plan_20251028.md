# Development Plan - October 28, 2025

## Phase 1: Context Discovery - COMPLETE âœ…

**Sources Analyzed:**
- âœ… Repository status (main branch, clean working tree)
- âœ… README.md (session handover, next priorities, limitations)
- âœ… Recent PRs (#11, #10, #9, #8, #7, #6, #5, #4, #3, #2)
- âœ… Open issues (none currently)
- âœ… Planning documents (codex_improvement_plan.md, claude_improvement_plan.md, plan_20251024.md)
- âœ… Current implementation status (6 src files, 5 test files, 65 tests passing)

---

## Recently Completed (Context)

âœ… **PR #10** (Oct 28): Genetic crossover operators
- Uniform crossover with intelligent filter blending
- Configurable reproduction rates (30% crossover, 50% mutation, 20% random)
- Fixed critical parent selection bug
- 14 new tests, all 65 tests passing

âœ… **PR #8** (Oct 27): Comprehensive fitness instrumentation
- Detailed timing breakdown, rejection statistics, example candidates
- JSON metrics export with visualization notebook
- 15 new tests for metrics tracking

âœ… **PR #2** (Oct 27): Gemini LLM integration
- Full LLM-guided mutation implementation
- Pydantic schemas with structured output
- Cost tracking and temperature scaling

---

## Phase 2: Task Synthesis

### ðŸ”´ CRITICAL PRIORITY
None blocking development currently.

### ðŸŸ¡ HIGH PRIORITY (Week 5-6 Deliverables)

#### Task #1: Multi-Strategy Evaluation System
- **Source**: codex_improvement_plan.md:21-24, README.md:336-341
- **Description**: Establish baseline by running classical sieving heuristics for comparison, define convergence stopping criteria and statistical tests
- **Why**: Validates that evolutionary loop reliably discovers higher-yield strategies (core research goal)
- **Estimated effort**: 6-8 hours (medium-large task)
- **Dependencies**: None (metrics system from PR #8 already complete)
- **Implementation approach**:
  - Add baseline comparison mode (classical quadratic sieve heuristics)
  - Implement statistical significance tests (t-test, effect size)
  - Add convergence detection (plateau detection, early stopping)
  - Create comparison visualization in notebook
- **Files to modify**:
  - `prototype.py`: Add baseline strategy generator
  - `prototype.py`: Add `--compare-baseline` CLI flag
  - `analysis/visualize_metrics.ipynb`: Add comparison plots
  - `tests/test_baseline.py`: New test file
  - `README.md`: Document comparison mode

#### Task #2: Reproducible Runs with RNG Seeds
- **Source**: codex_improvement_plan.md:10
- **Description**: Add configuration for RNG seeds to enable reproducible experiments
- **Why**: Essential for scientific validation and debugging
- **Estimated effort**: 2-3 hours (small task)
- **Dependencies**: None
- **Implementation approach**:
  - Add `--seed` CLI argument
  - Seed all `random` module calls
  - Add seed to metrics export for reproducibility
  - Document seeding behavior in README
- **Files to modify**:
  - `prototype.py`: Add seed parameter and seeding logic
  - `src/config.py`: Add seed to Config dataclass
  - `tests/test_integration.py`: Add reproducibility test
  - `README.md`: Document `--seed` flag

### ðŸŸ¢ MEDIUM PRIORITY (Week 7-8+ Enhancements)

#### Task #3: Adaptive Mutation Rates
- **Source**: codex_improvement_plan.md:16
- **Description**: Introduce adaptive mutation rates driven by population diversity metrics
- **Why**: Prevents premature convergence, improves exploration-exploitation balance
- **Estimated effort**: 4-5 hours (medium task)
- **Dependencies**: Task #1 (diversity metrics)
- **Implementation approach**:
  - Implement diversity metric (strategy parameter variance)
  - Adjust mutation rate dynamically based on diversity
  - Add diversity tracking to metrics export
- **Files to modify**:
  - `prototype.py`: Add diversity calculation
  - `prototype.py`: Add adaptive rate logic to EvolutionaryEngine
  - `tests/test_adaptive.py`: New test file

#### Task #4: Meta-Learning for Temperature/Crossover Tuning
- **Source**: codex_improvement_plan.md:35
- **Description**: Meta-learning loop that adjusts mutation/crossover operators based on historical success
- **Why**: Automatically tunes hyperparameters for better performance
- **Estimated effort**: 6-8 hours (medium-large task)
- **Dependencies**: Task #1 (historical success tracking)
- **Implementation approach**:
  - Track which mutation types succeeded
  - Adjust temperature/crossover rates based on success patterns
  - Add meta-learning mode to CLI
- **Files to modify**:
  - `src/llm/gemini.py`: Add success tracking
  - `prototype.py`: Add meta-learning engine
  - `tests/test_meta_learning.py`: New test file

#### Task #5: Resource Usage Monitoring
- **Source**: codex_improvement_plan.md:24
- **Description**: Capture resource usage (CPU time, memory) to monitor efficiency
- **Why**: Enables scaling toward realistic GNFS workloads
- **Estimated effort**: 2-3 hours (small task)
- **Dependencies**: None
- **Implementation approach**:
  - Add `psutil` for memory/CPU tracking
  - Include resource metrics in JSON export
  - Add resource usage to visualization notebook
- **Files to modify**:
  - `requirements.txt`: Add `psutil`
  - `prototype.py`: Add resource tracking to evaluation
  - `analysis/visualize_metrics.ipynb`: Add resource plots

### ðŸ”µ LOW PRIORITY (Nice-to-have)

#### Task #6: Production Logging Configuration
- **Source**: README.md:345-348, PR #2 review feedback
- **Description**: Add logging config with environment-based levels (DEBUG/INFO/WARNING)
- **Why**: Helps with debugging and production deployment
- **Estimated effort**: 1-2 hours (quick win)
- **Dependencies**: None
- **Implementation approach**:
  - Add `logging` configuration in config.py
  - Replace print statements with logger calls
  - Add LOG_LEVEL to .env.example
- **Files to modify**:
  - `src/config.py`: Add logging setup
  - `prototype.py`: Replace prints with logging
  - `.env.example`: Add LOG_LEVEL

#### Task #7: Extract Magic Numbers to Config
- **Source**: README.md:349-353, PR #2 review feedback
- **Description**: Move hardcoded constants (0.2 elite selection, 0.8/1.2 temps) to config
- **Why**: Improves tunability, but current values work well
- **Estimated effort**: 1-2 hours (quick win)
- **Dependencies**: None
- **Implementation approach**:
  - Add constants to Config dataclass
  - Update EvolutionaryEngine to use config values
  - Add CLI flags for tuning (optional)
- **Files to modify**:
  - `src/config.py`: Add elite_fraction, temp_base, temp_max
  - `prototype.py`: Use config values instead of literals
  - `README.md`: Document configuration options

#### Task #8: Expand Heuristic Vocabulary
- **Source**: codex_improvement_plan.md:17
- **Description**: Include residue classes from quadratic residues and trial division depth
- **Why**: Richer strategy space, but requires domain expertise
- **Estimated effort**: 4-6 hours (medium task)
- **Dependencies**: Research into GNFS mathematical theory
- **Implementation approach**:
  - Research quadratic residue theory
  - Add new strategy parameters (trial_division_depth, qr_filters)
  - Update LLM prompts to propose new parameters
  - Extend schema validation

---

## Phase 3: Prioritized Implementation Plan

### ðŸŽ¯ Recommended Next Actions

#### **START WITH: Task #2 - Reproducible Runs**
**Why First?**
- Quick win (2-3 hours) builds momentum
- Essential foundation for all other research tasks
- No dependencies, can be done immediately
- Enables scientific validation of future improvements

**Implementation Steps:**
1. Add `--seed INT` argument to CLI (prototype.py:720+)
2. Seed `random` module at start of main()
3. Add seed field to EvaluationMetrics dataclass
4. Include seed in JSON export
5. Add test for reproducibility (same seed â†’ same results)
6. Document seeding in README

**Test Plan:**
- Run with same seed twice, verify identical fitness scores
- Run with different seeds, verify different results
- Verify seed appears in exported metrics JSON

---

#### **THEN PROCEED TO: Task #1 - Multi-Strategy Evaluation**
**Why Second?**
- High-impact Week 5-6 deliverable
- Validates core research hypothesis
- Builds on completed PR #8 (metrics system)
- Enables all statistical analysis tasks

**Implementation Steps:**
1. Add classical baseline strategies (quadratic sieve style)
2. Implement comparison mode: `--compare-baseline`
3. Add statistical tests (scipy.stats.ttest_ind, cohen_d)
4. Implement convergence detection (fitness plateau for N generations)
5. Add comparison visualization to notebook
6. Document comparison methodology

**Test Plan:**
- Baseline strategies produce reasonable fitness scores
- Statistical tests correctly identify significant differences
- Convergence detection triggers early stopping
- Comparison plots render correctly

---

### Session Goals
- [x] Complete comprehensive planning (this document)
- [ ] Implement reproducible runs with RNG seeds (Task #2)
- [ ] Write tests for reproducibility
- [ ] Update documentation with seeding instructions
- [ ] Start design for multi-strategy evaluation (Task #1)

---

## Implementation Timeline Estimate

| Timeframe | Task | Priority | Effort |
|-----------|------|----------|--------|
| **This Session (Today)** | Task #2: Reproducible Runs | HIGH | 2-3h |
| **Next Session** | Task #1: Multi-Strategy Evaluation | HIGH | 6-8h |
| **Week 2** | Task #5: Resource Monitoring | MEDIUM | 2-3h |
| **Week 2** | Task #6: Logging Config | LOW | 1-2h |
| **Week 3** | Task #3: Adaptive Mutation | MEDIUM | 4-5h |
| **Week 4** | Task #4: Meta-Learning | MEDIUM | 6-8h |
| **Future** | Task #7, #8 | LOW | TBD |

---

## Known Issues & Blockers

**Current Blockers:** None

**Potential Risks:**
- Task #1 requires statistical expertise (mitigate: use standard scipy tests)
- Task #4 meta-learning complexity may exceed estimates (mitigate: start with simple heuristics)
- Task #8 requires GNFS domain knowledge (mitigate: consult literature, start with simple extensions)

---

## Key Insights from Planning

1. **Strong Foundation**: PRs #2, #8, #10 provide excellent infrastructure
   - LLM integration working reliably
   - Metrics system captures all needed data
   - Crossover operators add genetic diversity

2. **Clear Research Path**: codex_improvement_plan.md provides structured roadmap
   - Week 1-2: Instrumentation âœ… (completed PR #8)
   - Week 3-4: Crossover âœ… (completed PR #10)
   - Week 5-6: Baseline comparison (next priority)
   - Week 7-8: Meta-learning (future work)

3. **Low-Hanging Fruit**: Tasks #2, #5, #6, #7 are quick wins
   - Can be completed in 1-3 hours each
   - Build confidence and momentum
   - No complex dependencies

4. **Research Validation**: Task #1 is critical milestone
   - Validates core hypothesis: "LLM evolution > rule-based"
   - Enables publication/presentation of results
   - Provides statistical rigor

---

## Next Steps

**Recommended Path:** Start with Task #2 (Reproducible Runs) to build foundation for research validation.

**Alternative Paths:**
1. **Research-first**: Jump to Task #1 (Multi-Strategy Evaluation) for immediate validation
2. **Quick wins**: Complete Tasks #6 + #7 (Logging + Config) in 2-4 hours
3. **Infrastructure**: Task #5 (Resource Monitoring) for scaling preparation

**To proceed:**
1. Create feature branch: `git checkout -b feature/reproducible-runs`
2. Implement Task #2 following TDD workflow
3. Write tests first (red phase)
4. Implement functionality (green phase)
5. Create PR with all checks passing

---

## Related Documents
- `codex_improvement_plan.md` - Original roadmap and guiding objectives
- `claude_improvement_plan.md` - LLM integration plan (completed)
- `plan_20251024.md` - Gemini integration detailed plan (completed)
- `README.md` - Session handover and learnings
- `CLAUDE.md` - Development patterns and critical learnings
